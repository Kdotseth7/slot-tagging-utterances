{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c00405d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import contractions\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import islice\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "from seqeval.metrics import f1_score\n",
    "from seqeval.scheme import IOB2\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from spacy.tokenizer import Tokenizer\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "# Set device = CUDA if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34b898e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Shape: (2312, 2)\n",
      "Train Set with unequal rows removed Shape:  (2253, 2)\n",
      "Test Set Shape: (981, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reading CSV File into Pandas DataFrame\n",
    "\n",
    "# Reading Train Dataset into DataFrame\n",
    "dataF = pd.read_csv('Data/hw2_train.csv', index_col = 0)\n",
    "dataF.columns = ['texts', 'tags']\n",
    "print('Train Set Shape:', dataF.shape)\n",
    "# print(dataF.tail())\n",
    "\n",
    "# Removing unequal texts and tags from train dataset\n",
    "list_of_dict = []\n",
    "for idx, row in dataF.iterrows():\n",
    "    temp_dict = {}\n",
    "    len_text = len(row['texts'].split())\n",
    "    len_tag = len(row['tags'].split())\n",
    "    if(len_text == len_tag):\n",
    "        temp_dict['texts'] = row['texts']\n",
    "        temp_dict['tags'] = row['tags']\n",
    "        list_of_dict.append(temp_dict)\n",
    "df = pd.DataFrame.from_dict(list_of_dict)\n",
    "print('Train Set with unequal rows removed Shape: ', df.shape)\n",
    "# print(df.tail())\n",
    "\n",
    "# Reading Test Dataset into DataFrame\n",
    "test_data = pd.read_csv('Data/hw2_test.csv', index_col = 0)\n",
    "test_data.columns = ['texts']\n",
    "print('Test Set Shape:', test_data.shape)\n",
    "# print(test_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d233c178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape:  (1689, 2)\n",
      "Test Data Shape:  (564, 2)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the Training dataset into the Training set and Validation set\n",
    "train_data, val_data = train_test_split(df,\n",
    "                                        random_state = 0, \n",
    "                                        test_size = 0.25, \n",
    "                                        shuffle = True)\n",
    "print('Train Data Shape: ', train_data.shape)\n",
    "print('Test Data Shape: ', val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b379312a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2196009\n"
     ]
    }
   ],
   "source": [
    "# Pre-Trained GloVe Word Embeddings\n",
    "glove = pd.read_csv('Data/gloVe/glove.840B.300d.txt', sep = ' ', quoting = 3, header = None, index_col = 0)\n",
    "glove_embedding = {key: val.values for key, val in glove.T.items()}\n",
    "print(len(glove_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68c21e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Shape:  (2196009,)\n",
      "Embeddings Shape:  (2196009, 300)\n"
     ]
    }
   ],
   "source": [
    "# Create NumPy Array for Vocab and Emeddings\n",
    "vocab = list(glove_embedding.keys())\n",
    "embeddings = list(glove_embedding.values())\n",
    "\n",
    "vocab = np.array(vocab)\n",
    "embeddings = np.array(embeddings)\n",
    "print('Vocab Shape: ', vocab.shape)\n",
    "print('Embeddings Shape: ', embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbea4f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2196011,)\n",
      "(2196011, 300)\n"
     ]
    }
   ],
   "source": [
    "# Insert '<pad>' and '<unk>' tokens at start of vocab\n",
    "vocab = np.insert(vocab, 0, '<pad>')\n",
    "vocab = np.insert(vocab, 1, '<unk>')\n",
    "print(vocab.shape)\n",
    "\n",
    "# Insert embeddings for pad and unk tokens at top of embeddings\n",
    "embedding_pad = np.zeros((1, \n",
    "                          embeddings.shape[1]))\n",
    "embedding_unk = np.mean(embeddings, \n",
    "                        axis = 0, \n",
    "                        keepdims = True)\n",
    "embeddings = np.vstack((embedding_pad, \n",
    "                        embedding_unk, \n",
    "                        embeddings))\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd82ad73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'B_country', 1: 'B_person', 2: 'I_release_year', 3: 'B_cast', 4: 'B_subject', 5: 'B_char', 6: 'I_producer', 7: 'I_language', 8: 'B_movie', 9: 'B_release_year', 10: 'B_genre', 11: 'I_movie', 12: 'I_char', 13: 'B_language', 14: 'B_director', 15: 'I_genre', 16: 'I_country', 17: 'B_mpaa_rating', 18: 'I_mpaa_rating', 19: 'I_subject', 20: 'I-movie', 21: 'O', 22: 'I_cast', 23: 'I_director', 24: 'I_person', 25: 'B_location', 26: 'B_producer'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# Dictionary for words\n",
    "word2idx = { term: idx for idx, term in enumerate(vocab) }\n",
    "word2idx['<pad>'] = 0\n",
    "word2idx['<unk>'] = 1\n",
    "idx2word = { idx: word for word,idx in word2idx.items() }\n",
    "# print(len(word2idx))\n",
    "\n",
    "# for k,v in sorted(word2idx.items(), key = operator.itemgetter(1))[:50]:\n",
    "#     print(k,v)\n",
    "\n",
    "# Dicitionary for tags\n",
    "tag_set = set()\n",
    "tag_count_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    temp = row['tags'].split()\n",
    "    for item in temp:\n",
    "        tag_set.add(item)\n",
    "        if item not in tag_count_dict:\n",
    "            tag_count_dict[item] = 1\n",
    "        else:\n",
    "            tag_count_dict[item] = tag_count_dict[item] + 1\n",
    "\n",
    "tag2idx = { tag: idx for idx, tag in enumerate(tag_set) }\n",
    "idx2tag = { idx: word for word, idx in tag2idx.items() }\n",
    "print(idx2tag)\n",
    "\n",
    "TAG_COUNT = len(tag2idx)\n",
    "print(TAG_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5e66e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SlotTagger Class for DataLoader\n",
    "class SlotTaggerDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 data: pd.DataFrame):\n",
    "        self.data = data\n",
    "        self.texts = self.data['texts']\n",
    "        if 'tags' in self.data.columns:\n",
    "            self.tags = self.data['tags']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, \n",
    "                    idx: int):\n",
    "        # Enoding Text\n",
    "        text = self.texts.iloc[idx]\n",
    "        encoded_text = self.encode_text(text)\n",
    "        \n",
    "        # Encoding Tags if they exist\n",
    "        if 'tags' in self.data.columns:\n",
    "            tag = self.tags.iloc[idx]\n",
    "            encoded_tag = self.encode_tag(tag)\n",
    "            return encoded_text, encoded_tag \n",
    "        else:\n",
    "            return encoded_text\n",
    "        \n",
    "    # Tokenize    \n",
    "    def tokenize(self, \n",
    "                 text: str):\n",
    "        return [i.text for i in tokenizer(text)]\n",
    "    \n",
    "    # Encode Text\n",
    "    def encode_text(self, \n",
    "                    text):\n",
    "        text_list = [word for word in self.tokenize(text)]\n",
    "        text_vector = []\n",
    "        for word in text_list:\n",
    "            if word in word2idx:\n",
    "                text_vector.append(word2idx[word])\n",
    "            else:\n",
    "                text_vector.append(1)\n",
    "        return text_vector\n",
    "    \n",
    "    # Enocde Tags\n",
    "    def encode_tag(self, \n",
    "                   tag):\n",
    "        tag_list = [word for word in self.tokenize(tag)]\n",
    "        tag_vector = [tag2idx[word] for word in tag_list]\n",
    "        return tag_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b8d42fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slot Tagger Object for DataLoader\n",
    "train_ds = SlotTaggerDataset(train_data)\n",
    "# print(train_ds[0])\n",
    "val_ds = SlotTaggerDataset(val_data)\n",
    "# print(val_ds[0])\n",
    "test_ds = SlotTaggerDataset(test_data)\n",
    "# print(test_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d9aae1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Data Loader\n",
    "def custom_collate_fn(batch):\n",
    "    if isinstance(batch[0], list):\n",
    "        texts_tensor = [torch.tensor(text) for text in batch]\n",
    "\n",
    "        lengths = [len(text) for text in batch]\n",
    "        lengths = torch.tensor(lengths)\n",
    "\n",
    "        texts_padded = pad_sequence(texts_tensor, batch_first = True, padding_value = 0)\n",
    "\n",
    "        return texts_padded, lengths\n",
    "\n",
    "    else:\n",
    "        texts, tags = zip(*batch)\n",
    "\n",
    "        texts_tensor = [torch.tensor(text) for text in texts]\n",
    "        tags_tensor = [torch.tensor(tag) for tag in tags]\n",
    "\n",
    "        lengths = [len(text) for text in texts]\n",
    "        lengths = torch.tensor(lengths)\n",
    "\n",
    "        texts_padded = pad_sequence(texts_tensor, batch_first = True, padding_value = 0)\n",
    "        tags_padded = pad_sequence(tags_tensor, batch_first = True, padding_value = 0)\n",
    "\n",
    "        return texts_padded, tags_padded, lengths\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(train_ds, \n",
    "                          batch_size = BATCH_SIZE, \n",
    "                          shuffle = True, \n",
    "                          collate_fn = custom_collate_fn)\n",
    "val_loader = DataLoader(val_ds, \n",
    "                        batch_size = BATCH_SIZE, \n",
    "                        shuffle = True, \n",
    "                        collate_fn = custom_collate_fn)\n",
    "\n",
    "test_loader = DataLoader(test_ds, \n",
    "                        batch_size = 1, \n",
    "                        shuffle = False, \n",
    "                        collate_fn = custom_collate_fn)\n",
    "\n",
    "# print(list(islice(train_loader, 1)))\n",
    "\n",
    "assert train_data.shape[0] == len(train_loader.dataset)\n",
    "assert val_data.shape[0] == len(val_loader.dataset)\n",
    "assert test_data.shape[0] == len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "78f9fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN Model with 1 hidden layer\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, \n",
    "                 embedding_dim, \n",
    "                 hidden_dim, \n",
    "                 output_dim, \n",
    "                 n_layers, \n",
    "                 bidirectional, \n",
    "                 dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initialize Embedding Layer with Pre-Trained Embeddings (Vector Sequences)\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(embeddings).float())\n",
    "        # LSTM layer process the vector sequences \n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                            hidden_dim,\n",
    "                            num_layers = n_layers,\n",
    "                            bidirectional = bidirectional,\n",
    "#                             dropout = dropout,\n",
    "                            batch_first = True)\n",
    "#         # We use dropout before the final layer to improve with regularization\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "        # Dense layer to predict \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, \n",
    "                x, \n",
    "                x_lengths):\n",
    "        embedded = self.embedding(x)\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, \n",
    "                                                            x_lengths, \n",
    "                                                            batch_first = True, \n",
    "                                                            enforce_sorted = False) # Pack sequence\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output, \n",
    "                                                                  batch_first = True) # Unpack sequence\n",
    "#         output = self.dropout(output)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b4cf2157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (embedding): Embedding(2196011, 300)\n",
      "  (lstm): LSTM(300, 20, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=20, out_features=27, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(32)\n",
    "\n",
    "EMBEDDING_DIM = embeddings.shape[1]\n",
    "HIDDEN_DIM = 20\n",
    "OUTPUT_DIM = TAG_COUNT\n",
    "NUM_LAYERS = 2\n",
    "BIDIRECTION = False\n",
    "DROPOUT = 0.2\n",
    "\n",
    "model = LSTM(EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            NUM_LAYERS, \n",
    "            BIDIRECTION, \n",
    "            DROPOUT).to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cf60ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeezed_list(my_list):\n",
    "    temp_list = [int(element) for element in my_list]\n",
    "    return temp_list  \n",
    "\n",
    "def slice_list(my_list, slice_increment):\n",
    "    return [my_list[i : i + slice_increment] for i in range(0, len(my_list), slice_increment)]\n",
    "\n",
    "def convert_idx_to_tags(lol, isTensor):\n",
    "    iob_list = []\n",
    "    for list_element in lol:\n",
    "        if (isTensor):\n",
    "            list_element = list_element.numpy() \n",
    "        iob = [idx2tag[index] for index in list_element]\n",
    "        iob_list.append(iob)\n",
    "    return iob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fade282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Train Function\n",
    "def train(loader, \n",
    "          model, \n",
    "          optimizer, \n",
    "          loss_fn):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    pbar = tqdm(loader)\n",
    "    for x, y, lengths in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(x, lengths)\n",
    "        \n",
    "        y_pred = y_pred.view(-1, y_pred.shape[-1])\n",
    "        y = torch.flatten(y)\n",
    "        \n",
    "        loss = loss_fn(y_pred, y)\n",
    "        pbar.set_postfix({'Loss': loss.item()})\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # Calculate gradients for w/b\n",
    "        loss.backward()  \n",
    "        # Update weights according to optimizer rules\n",
    "        optimizer.step()          \n",
    "    return sum(losses) / len(losses)\n",
    "\n",
    "# Model Evaluate Function\n",
    "def evaluate(loader, \n",
    "             model, \n",
    "             loss_fn, \n",
    "             score_fn):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for x, y, lengths in tqdm(loader):\n",
    "        y_pred = model(x, lengths)\n",
    "        \n",
    "        max_len = x.shape[1]\n",
    "              \n",
    "        y_pred = y_pred.view(-1, y_pred.shape[-1])\n",
    "        y = torch.flatten(y)\n",
    "        \n",
    "\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        tags_iob = convert_idx_to_tags(slice_list(y, max_len), True)\n",
    "\n",
    "        max_preds = y_pred.argmax(dim = 1, keepdim = True) # Get the index of the max probability\n",
    "        predictions_iob = convert_idx_to_tags(slice_list((squeezed_list(max_preds)), max_len), False)\n",
    "    \n",
    "    score = score_fn(tags_iob, predictions_iob, scheme = IOB2)\n",
    "    return tags_iob, predictions_iob, sum(losses) / len(losses), score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bc19c22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 53/53 [00:00<00:00, 107.58it/s, Loss=1.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  2.1276060747650436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 255.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.8695652173913043\n",
      "Val Loss:  1.606158905559116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 53/53 [00:00<00:00, 170.06it/s, Loss=1.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  1.3511050399744287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 307.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.8704663212435233\n",
      "Val Loss:  1.1327585909101698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 53/53 [00:00<00:00, 163.58it/s, Loss=0.802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.9240433663692115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 314.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.8669950738916256\n",
      "Val Loss:  0.7596846785810258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 53/53 [00:00<00:00, 170.99it/s, Loss=0.598]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.6240231130483016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 308.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.8686131386861314\n",
      "Val Loss:  0.5343639834059609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 53/53 [00:00<00:00, 168.57it/s, Loss=0.416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.4382056436448727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 294.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.935064935064935\n",
      "Val Loss:  0.40008341438240475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 53/53 [00:00<00:00, 169.88it/s, Loss=0.276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.3272100068488211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 316.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9591078066914499\n",
      "Val Loss:  0.3221878740522597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 53/53 [00:00<00:00, 174.10it/s, Loss=0.227]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.2544457926502768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 319.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9036144578313252\n",
      "Val Loss:  0.27196597970194286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 53/53 [00:00<00:00, 167.57it/s, Loss=0.195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.20670542683241502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 307.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.8929889298892989\n",
      "Val Loss:  0.2327897689408726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 53/53 [00:00<00:00, 174.42it/s, Loss=0.155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.1718649113515638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 315.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9266409266409267\n",
      "Val Loss:  0.21253516359461677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 53/53 [00:00<00:00, 175.40it/s, Loss=0.148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.14796796455135885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 317.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9274193548387097\n",
      "Val Loss:  0.19231455110841328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 53/53 [00:00<00:00, 170.79it/s, Loss=0.114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.12448634235364087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 316.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9528535980148882\n",
      "Val Loss:  0.18247787281870842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 172.97it/s, Loss=0.0906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.1082897274842802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 313.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9733656174334141\n",
      "Val Loss:  0.1844098638329241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 53/53 [00:00<00:00, 172.51it/s, Loss=0.088]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.09632760201984981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 310.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9186602870813397\n",
      "Val Loss:  0.16565537908011013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 53/53 [00:00<00:00, 170.92it/s, Loss=0.104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.08766515862266973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 310.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9724137931034483\n",
      "Val Loss:  0.16417844427956474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 53/53 [00:00<00:00, 167.42it/s, Loss=0.118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.07728591013067174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 309.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9469696969696969\n",
      "Val Loss:  0.168395244412952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 173.61it/s, Loss=0.0693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.07240664410703587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 285.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9393939393939394\n",
      "Val Loss:  0.14812188512749142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 171.30it/s, Loss=0.0769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.0690774326476286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 326.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9281045751633986\n",
      "Val Loss:  0.15577182256513172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 173.34it/s, Loss=0.0575]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.06072799608392535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 309.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9491525423728814\n",
      "Val Loss:  0.15426404236091507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 171.39it/s, Loss=0.0798]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.05445612292244749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 300.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.935064935064935\n",
      "Val Loss:  0.15734942878286043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 173.51it/s, Loss=0.0327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.05122112071598476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 308.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9530685920577618\n",
      "Val Loss:  0.15140573928753534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 172.82it/s, Loss=0.0665]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.05032940177282073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 307.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9466192170818506\n",
      "Val Loss:  0.15486299494902292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 172.63it/s, Loss=0.0282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.04657049617677365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 306.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9591836734693877\n",
      "Val Loss:  0.16307804940475357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 174.51it/s, Loss=0.0447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.04658604915833698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 305.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.962121212121212\n",
      "Val Loss:  0.15937109022504753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 159.47it/s, Loss=0.0366]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.04259015921995325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 306.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9344262295081968\n",
      "Val Loss:  0.1551487934258249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 169.46it/s, Loss=0.0481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.039607807396436635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 316.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9724770642201834\n",
      "Val Loss:  0.15716904691523975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 172.93it/s, Loss=0.0285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.03515229542862694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 311.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9429657794676807\n",
      "Val Loss:  0.15563724810878435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 173.89it/s, Loss=0.0288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.03239620990067158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 311.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9787234042553191\n",
      "Val Loss:  0.14893117008937728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 169.67it/s, Loss=0.0122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.032020561203782286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 311.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9405940594059405\n",
      "Val Loss:  0.15761304191417164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 172.45it/s, Loss=0.0182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.03167505047442216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 306.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9382716049382717\n",
      "Val Loss:  0.1606156943986813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 171.87it/s, Loss=0.0239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.028507802617859165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 315.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9737609329446064\n",
      "Val Loss:  0.16018170966870254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 171.33it/s, Loss=0.0122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.02669730005820967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 312.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.967741935483871\n",
      "Val Loss:  0.1682089041504595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 169.69it/s, Loss=0.0422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.028324304746007018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 309.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9722222222222222\n",
      "Val Loss:  0.16944634541869164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 173.30it/s, Loss=0.0418]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.025979030244755296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 307.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.948905109489051\n",
      "Val Loss:  0.16865281419207653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 171.52it/s, Loss=0.0283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.023585767977220833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 311.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9683544303797469\n",
      "Val Loss:  0.1629291098150942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 170.80it/s, Loss=0.0274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.023197701710434455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 312.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9574468085106383\n",
      "Val Loss:  0.164430212850372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 170.25it/s, Loss=0.0203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.021371376683127205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 309.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9712918660287081\n",
      "Val Loss:  0.15910406907399496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 53/53 [00:00<00:00, 169.47it/s, Loss=0.017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.027741269876231562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 317.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9651741293532338\n",
      "Val Loss:  0.1735167863468329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 53/53 [00:00<00:00, 172.54it/s, Loss=0.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.02620627263666324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 311.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9587628865979382\n",
      "Val Loss:  0.16599324055843884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 164.44it/s, Loss=0.0327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.030397434086310415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 310.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.90625\n",
      "Val Loss:  0.1789996615714497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 169.39it/s, Loss=0.0175]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.035608425209263585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 312.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9517684887459806\n",
      "Val Loss:  0.1637874347054296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 158.03it/s, Loss=0.0134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.029647873943003843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 307.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.967032967032967\n",
      "Val Loss:  0.15521205382214653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 170.03it/s, Loss=0.0186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.028388791682444653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 325.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.925764192139738\n",
      "Val Loss:  0.18433673472868073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 172.26it/s, Loss=0.0174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.023480765978401562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 307.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9464285714285714\n",
      "Val Loss:  0.16488873875803417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 171.46it/s, Loss=0.0122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.01980766900024324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 309.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9750692520775623\n",
      "Val Loss:  0.16663892360197174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 170.22it/s, Loss=0.0257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.018145975006638834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 316.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9459459459459459\n",
      "Val Loss:  0.16964025174578032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 172.51it/s, Loss=0.0112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.017443956693036937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 318.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9052631578947369\n",
      "Val Loss:  0.16509786393079492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 53/53 [00:00<00:00, 171.75it/s, Loss=0.00674]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.015904559323318163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 287.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9535864978902953\n",
      "Val Loss:  0.156859102141526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 172.13it/s, Loss=0.0103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.015106180208331009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 312.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.923076923076923\n",
      "Val Loss:  0.17001528520550993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 175.09it/s, Loss=0.0072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.015433565713465214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 310.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9623188405797102\n",
      "Val Loss:  0.1846312607328097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 53/53 [00:00<00:00, 173.87it/s, Loss=0.0327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.015799477459195087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 18/18 [00:00<00:00, 310.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.9465648854961831\n",
      "Val Loss:  0.16569840970138708\n"
     ]
    }
   ],
   "source": [
    "# Model Training on Train dataset and Evaluation on Validation dataset\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr = 0.01)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "score_fn = f1_score\n",
    "\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "f1_score_list = []\n",
    "n_epochs = 50\n",
    "best_acc = 0\n",
    "PATH = f'best-model.pt'\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Model Training\n",
    "    train_loss = train(train_loader, \n",
    "                     model, \n",
    "                     optimizer, \n",
    "                     loss_fn)\n",
    "    print('Train Loss: ', train_loss)\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    # Model Evaluation\n",
    "    tags, predictions, val_loss, accuracy = evaluate(val_loader, \n",
    "                                                       model, \n",
    "                                                       loss_fn, \n",
    "                                                       score_fn)\n",
    "    print('Val Accuracy: ', accuracy)\n",
    "    print('Val Loss: ', val_loss)\n",
    "    val_loss_list.append(val_loss)\n",
    "    f1_score_list.append(accuracy)\n",
    "    \n",
    "    # Save model if Validation F1_Score is greather than 75%\n",
    "#     if accuracy > best_acc and accuracy > 0.75:\n",
    "#         torch.save(model.state_dict(), PATH)\n",
    "#         cm = multilabel_confusion_matrix(labels, predictions)\n",
    "\n",
    "# print('Train Loss List: ', train_loss_list)  \n",
    "# print('Val Loss List: ', val_loss_list)\n",
    "# print('Acc List: ', f1_score_list)\n",
    "\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ae6188d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embedding): Embedding(2196011, 300)\n",
       "  (lstm): LSTM(300, 20, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=20, out_features=27, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save and Load the Model\n",
    "saved_model = LSTM(EMBEDDING_DIM, \n",
    "                   HIDDEN_DIM, \n",
    "                   OUTPUT_DIM, \n",
    "                   NUM_LAYERS, \n",
    "                   BIDIRECTION, \n",
    "                   DROPOUT).to(device)\n",
    "\n",
    "saved_model.load_state_dict(torch.load(PATH))\n",
    "saved_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ec96c585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 981/981 [00:00<00:00, 2059.89it/s]\n",
      "/var/folders/hk/l7897jp170bb9tbb20n80tz00000gn/T/ipykernel_85355/2706907146.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  predictions = np.array(predictions)\n"
     ]
    }
   ],
   "source": [
    "def predict(loader, \n",
    "            model):\n",
    "    predictions = []\n",
    "    for x, lengths in tqdm(loader):\n",
    "        with torch.no_grad():\n",
    "            y_pred = saved_model.forward(x, lengths)\n",
    "            \n",
    "            max_len = x.shape[1]\n",
    "\n",
    "            y_pred = y_pred.view(-1, y_pred.shape[-1])\n",
    "\n",
    "            max_preds = y_pred.argmax(dim = 1, keepdim = True) # Get the index of the max probability\n",
    "            predictions_iob = convert_idx_to_tags(slice_list((squeezed_list(max_preds)), max_len), False)\n",
    "            predictions.append(predictions_iob)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "        \n",
    "predictions = predict(test_loader, saved_model)\n",
    "predictions = np.array(predictions)\n",
    "predictions = predictions.squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "273fe4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID                                      IOB Slot tags\n",
      "0      0                                        O O B_movie\n",
      "1      1                          O O O O O B_movie I_movie\n",
      "2      2                        O O O O O O B_movie I_movie\n",
      "3      3                                      O O O B_movie\n",
      "4      4                                      O O O B_movie\n",
      "..   ...                                                ...\n",
      "976  976        O O B_movie I_movie I_movie I_movie I_movie\n",
      "977  977                            O B_movie I_movie O O O\n",
      "978  978                O O O O O O B_producer I_producer O\n",
      "979  979  O O B_person I_director O O B_movie O O B_movi...\n",
      "980  980                   O O B_director O O O O B_country\n",
      "\n",
      "[981 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Creating Dictionary\n",
    "list_of_dict = []\n",
    "for i in range(0, len(predictions)):\n",
    "    temp_dict = {}\n",
    "    temp_dict[\"ID\"] = i\n",
    "    temp_dict[\"IOB Slot tags\"] = ' '.join(predictions[i])\n",
    "    list_of_dict.append(temp_dict)\n",
    "\n",
    "# Converting Dictionary to CSV and compress it for submission to CodaLab\n",
    "tags_df = pd.DataFrame.from_dict(list_of_dict)\n",
    "tags_df.to_csv('submission.csv.zip', compression = 'zip', index = False)\n",
    "print(tags_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
