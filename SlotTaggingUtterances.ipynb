{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c00405d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import contractions\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import islice\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "from seqeval.metrics import f1_score\n",
    "from seqeval.scheme import IOB2\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stopwords = nlp.Defaults.stop_words\n",
    "from spacy.tokenizer import Tokenizer\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "# Set device = CUDA if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34b898e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Shape: (2312, 2)\n",
      "Train Set with unequal rows removed Shape:  (2253, 2)\n",
      "Test Set Shape: (981, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reading CSV File into Pandas DataFrame\n",
    "\n",
    "# Reading Train Dataset into DataFrame\n",
    "dataF = pd.read_csv('Data/hw2_train.csv', index_col = 0)\n",
    "dataF.columns = ['texts', 'tags']\n",
    "print('Train Set Shape:', dataF.shape)\n",
    "# print(dataF.tail())\n",
    "\n",
    "# Removing unequal texts and tags from train dataset\n",
    "list_of_dict = []\n",
    "for idx, row in dataF.iterrows():\n",
    "    temp_dict = {}\n",
    "    len_text = len(row['texts'].split())\n",
    "    len_tag = len(row['tags'].split())\n",
    "    if(len_text == len_tag):\n",
    "        temp_dict['texts'] = row['texts']\n",
    "        temp_dict['tags'] = row['tags']\n",
    "        list_of_dict.append(temp_dict)\n",
    "df = pd.DataFrame.from_dict(list_of_dict)\n",
    "print('Train Set with unequal rows removed Shape: ', df.shape)\n",
    "# print(df.tail())\n",
    "\n",
    "# Reading Test Dataset into DataFrame\n",
    "test_df = pd.read_csv('Data/hw2_test.csv', index_col = 0)\n",
    "test_df.columns = ['texts']\n",
    "print('Test Set Shape:', test_df.shape)\n",
    "# print(test_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3bc08ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "def tokenize(text):\n",
    "    return [i.text for i in tokenizer(text)]\n",
    "    \n",
    "# Find Max Text and Tag Length\n",
    "def find_max_length(data):\n",
    "    max_length = 0\n",
    "    for row in data:\n",
    "        tokenized_row = tokenize(row)\n",
    "        if(len(tokenized_row) > max_length):\n",
    "            max_length = len(tokenized_row)\n",
    "    return max_length\n",
    "\n",
    "MAX_LENGTH = find_max_length(df['texts'])\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d233c178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape:  (1689, 2)\n",
      "Test Data Shape:  (564, 2)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the Training dataset into the Training set and Validation set\n",
    "train_data, val_data = train_test_split(df,\n",
    "                                        random_state = 0, \n",
    "                                        test_size = 0.25, \n",
    "                                        shuffle = True)\n",
    "print('Train Data Shape: ', train_data.shape)\n",
    "print('Test Data Shape: ', val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b379312a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2196009\n"
     ]
    }
   ],
   "source": [
    "# Pre-Trained GloVe Word Embeddings\n",
    "glove = pd.read_csv('Data/gloVe/glove.840B.300d.txt', sep = ' ', quoting = 3, header = None, index_col = 0)\n",
    "glove_embedding = {key: val.values for key, val in glove.T.items()}\n",
    "print(len(glove_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68c21e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Shape:  (2196009,)\n",
      "Embeddings Shape:  (2196009, 300)\n"
     ]
    }
   ],
   "source": [
    "# Create NumPy Array for Vocab and Emeddings\n",
    "vocab = list(glove_embedding.keys())\n",
    "embeddings = list(glove_embedding.values())\n",
    "\n",
    "vocab = np.array(vocab)\n",
    "embeddings = np.array(embeddings)\n",
    "print('Vocab Shape: ', vocab.shape)\n",
    "print('Embeddings Shape: ', embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbea4f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2196011,)\n",
      "(2196011, 300)\n"
     ]
    }
   ],
   "source": [
    "# Insert '<pad>' and '<unk>' tokens at start of vocab\n",
    "vocab = np.insert(vocab, 0, '<pad>')\n",
    "vocab = np.insert(vocab, 1, '<unk>')\n",
    "print(vocab.shape)\n",
    "\n",
    "# Insert embeddings for pad and unk tokens at top of embeddings\n",
    "embedding_pad = np.zeros((1, \n",
    "                          embeddings.shape[1]))\n",
    "embedding_unk = np.mean(embeddings, \n",
    "                        axis = 0, \n",
    "                        keepdims = True)\n",
    "embeddings = np.vstack((embedding_pad, \n",
    "                        embedding_unk, \n",
    "                        embeddings))\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd82ad73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2196011\n",
      "<pad> 0\n",
      "<unk> 1\n",
      ", 4\n",
      ". 5\n",
      "the 6\n",
      "and 7\n",
      "to 8\n",
      "of 9\n",
      "a 10\n",
      "in 11\n",
      "{2: 'I_mpaa_rating', 3: 'B_subject', 4: 'I_char', 5: 'I_movie', 6: 'I_language', 7: 'I_subject', 8: 'I_person', 9: 'B_genre', 10: 'I_director', 11: 'B_release_year', 12: 'I_genre', 13: 'B_cast', 14: 'B_producer', 15: 'I_country', 16: 'B_char', 17: 'O', 18: 'B_mpaa_rating', 19: 'B_movie', 20: 'B_language', 21: 'B_country', 22: 'B_location', 23: 'B_person', 24: 'I_producer', 25: 'I-movie', 26: 'I_release_year', 27: 'I_cast', 28: 'B_director', 0: '<pad>', 1: '<unk>'}\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "# Dictionary for words\n",
    "word2idx = { term: idx + 2 for idx, term in enumerate(vocab) }\n",
    "word2idx['<pad>'] = 0\n",
    "word2idx['<unk>'] = 1\n",
    "idx2word = { idx: word for word,idx in word2idx.items() }\n",
    "print(len(word2idx))\n",
    "\n",
    "for k,v in sorted(word2idx.items(), key = operator.itemgetter(1))[:10]:\n",
    "    print(k,v)\n",
    "\n",
    "# Dicitionary for tags\n",
    "tag_set = set()\n",
    "tag_count_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    temp = row['tags'].split()\n",
    "    for item in temp:\n",
    "        tag_set.add(item)\n",
    "        if item not in tag_count_dict:\n",
    "            tag_count_dict[item] = 1\n",
    "        else:\n",
    "            tag_count_dict[item] = tag_count_dict[item] + 1\n",
    "\n",
    "tag2idx = { tag: idx + 2 for idx, tag in enumerate(tag_set) }\n",
    "tag2idx['<pad>'] = 0\n",
    "tag2idx['<unk>'] = 1\n",
    "idx2tag = { idx: word for word, idx in tag2idx.items() }\n",
    "print(idx2tag)\n",
    "\n",
    "TAG_COUNT = len(tag2idx)\n",
    "print(TAG_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5e66e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SlotTagger Class for DataLoader\n",
    "class SlotTaggerDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 data: pd.DataFrame):\n",
    "        self.data = data\n",
    "        self.texts = self.data['texts']\n",
    "        self.tags = self.data['tags']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, \n",
    "                    idx: int):\n",
    "        # Enoding Text\n",
    "        text = self.texts.iloc[idx]\n",
    "#         text = self.preprocess_text(self.texts.iloc[idx])\n",
    "        text_tensor, len_text_vector = self.encode_text(text)\n",
    "        \n",
    "        # Encoding Tag\n",
    "        tag = self.tags.iloc[idx]\n",
    "        tag_tensor = self.encode_tag(tag)\n",
    "        \n",
    "        return text_tensor, tag_tensor, len_text_vector \n",
    "    \n",
    "    # Encode Text\n",
    "    def encode_text(self, \n",
    "                    text):\n",
    "        text_list = [word for word in self.tokenize(text)]\n",
    "        text_vector = []\n",
    "        for word in text_list:\n",
    "            if word in word2idx:\n",
    "                text_vector.append(word2idx[word])\n",
    "            else:\n",
    "                text_vector.append(1)\n",
    "        len_text_vector = len(text_vector)\n",
    "        padded_text_vector = text_vector + [word2idx['<pad>']] * (MAX_LENGTH - len(text_vector))\n",
    "        return torch.from_numpy(np.array(padded_text_vector)), len_text_vector\n",
    "    \n",
    "    # Enocde Label\n",
    "    def encode_tag(self, \n",
    "                   tag):\n",
    "        tag_list = [word for word in self.tokenize(tag)]\n",
    "        tag_vector = [tag2idx[word] for word in tag_list]\n",
    "        padded_tag_vector = tag_vector + [tag2idx['<pad>']] * (MAX_LENGTH - len(tag_vector))\n",
    "        ohe_tag_vector = np.eye(TAG_COUNT)[padded_tag_vector]\n",
    "        return torch.from_numpy(np.array(ohe_tag_vector))\n",
    "    \n",
    "    # Tokenization\n",
    "    def tokenize(self, \n",
    "                 text: str):\n",
    "        return tokenize(text)\n",
    "\n",
    "    # Text Lemmatization\n",
    "    def lemmatization(self, \n",
    "                      text):\n",
    "        doc = nlp(text)\n",
    "        temp_list = []\n",
    "        for token in doc:\n",
    "            temp_list.append(token)\n",
    "        return ' '.join(map(str, temp_list))\n",
    "    \n",
    "    # Stop Word Removal\n",
    "    def stopword_removal(self, \n",
    "                         text):\n",
    "        temp_list = []\n",
    "        for item in self.tokenize(text):\n",
    "            if item not in stopwords:\n",
    "                temp_list.append(item)\n",
    "        return ' '.join(temp_list)\n",
    "    \n",
    "    def preprocess_text(self, \n",
    "                        text):\n",
    "        # Removing all HTML Tags\n",
    "        text = re.sub(r'<.*?>', '', text)\n",
    "        # Removing links\n",
    "        text = re.sub(r'http\\S+', '', text)\n",
    "        # Remove Text Contractions\n",
    "        text = contractions.fix(text)\n",
    "        # Removing special characters and numbers\n",
    "        text = re.sub(r'[^A-Za-z0-9]+', ' ', text)\n",
    "        # Lemmatization\n",
    "        text = self.lemmatization(text)\n",
    "        # Stop word Removal\n",
    "        text = self.stopword_removal(text)\n",
    "        # Removing single characters\n",
    "        text = re.sub(r's+[a-zA-Z]s+', '', text)\n",
    "        # Replacing multi-spaces by a single space\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b8d42fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slot Tagger Object for DataLoader\n",
    "train_ds = SlotTaggerDataset(train_data)\n",
    "# print(train_ds[0])\n",
    "val_ds = SlotTaggerDataset(val_data)\n",
    "# print(val_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d9aae1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Data Loader\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_ds, \n",
    "                          batch_size = BATCH_SIZE, \n",
    "                          shuffle = True)\n",
    "val_loader = DataLoader(val_ds, \n",
    "                        batch_size = BATCH_SIZE, \n",
    "                        shuffle = True)\n",
    "\n",
    "# print(list(islice(train_loader, 1)))\n",
    "assert train_data.shape[0] == len(train_loader.dataset)\n",
    "assert val_data.shape[0] == len(val_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "78f9fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN Model with 1 hidden layer\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, \n",
    "                 embedding_dim, \n",
    "                 hidden_dim, \n",
    "                 output_dim, \n",
    "                 n_layers, \n",
    "                 bidirectional, \n",
    "                 dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initialize Embedding Layer with Pre-Trained Embeddings (Vector Sequences)\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(embeddings).float())\n",
    "        # LSTM layer process the vector sequences \n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                            hidden_dim,\n",
    "                            num_layers = n_layers,\n",
    "                            bidirectional = bidirectional,\n",
    "                            dropout = dropout,\n",
    "                            batch_first = False\n",
    "                           )\n",
    "#         # We use dropout before the final layer to improve with regularization\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "        # Dense layer to predict \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, \n",
    "                x, \n",
    "                x_lengths):\n",
    "        embedded = self.embedding(x)\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, x_lengths, batch_first= True, enforce_sorted = False) # Pack sequence\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output) # Unpack sequence\n",
    "#         output, (hidden, cell) = self.lstm(embedded)\n",
    "#         output = self.dropout(output)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b4cf2157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (embedding): Embedding(2196011, 300)\n",
      "  (lstm): LSTM(300, 20, dropout=0.2)\n",
      "  (fc): Linear(in_features=20, out_features=29, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(32)\n",
    "\n",
    "EMBEDDING_DIM = embeddings.shape[1]\n",
    "HIDDEN_DIM = 20\n",
    "OUTPUT_DIM = TAG_COUNT\n",
    "NUM_LAYERS = 1\n",
    "BIDIRECTION = False\n",
    "DROPOUT = 0.2\n",
    "\n",
    "model = LSTM(EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            NUM_LAYERS, \n",
    "            BIDIRECTION, \n",
    "            DROPOUT).to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cf60ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeezed_list(my_list):\n",
    "    temp_list = []\n",
    "    for element in my_list:\n",
    "        temp_list.append(int(element))\n",
    "    return temp_list    \n",
    "\n",
    "def slice_list(my_list):\n",
    "    return [my_list[i : i + BATCH_SIZE] for i in range(0, len(my_list), BATCH_SIZE)]\n",
    "\n",
    "def convert_idx_to_tags(list_of_lists):\n",
    "    iob_list = []\n",
    "    for element in list_of_lists:\n",
    "        iob = []\n",
    "        for index in element:\n",
    "            iob.append(idx2tag[index])\n",
    "        iob_list.append(iob)\n",
    "    return iob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fade282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Train Function\n",
    "def train(loader, \n",
    "          model, \n",
    "          optimizer, \n",
    "          loss_fn):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    pbar = tqdm(loader)\n",
    "    for x, y, lengths in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        print(x.shape, y.shape, lengths.shape)\n",
    "        \n",
    "        y_pred = model(x, lengths)\n",
    "        print(y_pred.shape)\n",
    "        \n",
    "        y_pred = y_pred.view(-1, y_pred.shape[-1])\n",
    "        y = y.view(-1, y.shape[-1])\n",
    "        \n",
    "        loss = loss_fn(y_pred, y)\n",
    "        pbar.set_postfix({'Loss: ': loss.item()})\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # Calculate gradients for w/b\n",
    "        loss.backward()  \n",
    "        # Update weights according to optimizer rules\n",
    "        optimizer.step()          \n",
    "    return sum(losses) / len(losses)\n",
    "\n",
    "# Model Evaluate Function\n",
    "def evaluate(loader, \n",
    "             model, \n",
    "             loss_fn, \n",
    "             score_fn):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for x, y in tqdm(loader):\n",
    "        y_pred = model(x)\n",
    "              \n",
    "        y_pred = y_pred.view(-1, y_pred.shape[-1])\n",
    "        y = y.view(-1, y.shape[-1])\n",
    "\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        max_preds = y_pred.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "        max_y = y.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "        \n",
    "        predictions_iob = convert_idx_to_tags(slice_list(squeezed_list(max_preds)))\n",
    "        tags_iob = convert_idx_to_tags(slice_list(squeezed_list(max_y)))\n",
    "    \n",
    "    score = score_fn(tags_iob, predictions_iob, scheme = IOB2)\n",
    "    return tags_iob, predictions_iob, sum(losses) / len(losses), score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bc19c22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 21]) torch.Size([64, 21, 29]) torch.Size([64])\n",
      "torch.Size([13, 64, 29])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (832) to match target batch_size (1344).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [89], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest-model.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Model Training\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train(train_loader, \n\u001b[1;32m     17\u001b[0m                      model, \n\u001b[1;32m     18\u001b[0m                      optimizer, \n\u001b[1;32m     19\u001b[0m                      loss_fn)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Loss: \u001b[39m\u001b[38;5;124m'\u001b[39m, train_loss)\n\u001b[1;32m     21\u001b[0m     train_loss_list\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn [88], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(loader, model, optimizer, loss_fn)\u001b[0m\n\u001b[1;32m     16\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, y_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     17\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m---> 19\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;124m'\u001b[39m: loss\u001b[38;5;241m.\u001b[39mitem()})\n\u001b[1;32m     21\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/Documents/pvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/pvenv/lib/python3.10/site-packages/torch/nn/modules/loss.py:1164\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/pvenv/lib/python3.10/site-packages/torch/nn/functional.py:3014\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3012\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3013\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3014\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (832) to match target batch_size (1344)."
     ]
    }
   ],
   "source": [
    "# Model Training on Train dataset and Evaluation on Validation dataset\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr = 0.001)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "score_fn = f1_score\n",
    "\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "f1_score_list = []\n",
    "n_epochs = 10\n",
    "best_acc = 0\n",
    "PATH = f'best-model.pt'\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Model Training\n",
    "    train_loss = train(train_loader, \n",
    "                     model, \n",
    "                     optimizer, \n",
    "                     loss_fn)\n",
    "    print('Train Loss: ', train_loss)\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    # Model Evaluation\n",
    "    labels, predictions, val_loss, accuracy = evaluate(val_loader, \n",
    "                                                       model, \n",
    "                                                       loss_fn, \n",
    "                                                       score_fn)\n",
    "    print('Val Accuracy: ', accuracy)\n",
    "    print('Val Loss: ', val_loss)\n",
    "    val_loss_list.append(val_loss)\n",
    "    f1_score_list.append(accuracy)\n",
    "    \n",
    "    # Save model if Validation F1_Score is greather than 75%\n",
    "#     if accuracy > best_acc and accuracy > 0.75:\n",
    "#         torch.save(model.state_dict(), PATH)\n",
    "#         cm = multilabel_confusion_matrix(labels, predictions)\n",
    "\n",
    "# print('Train Loss List: ', train_loss_list)  \n",
    "# print('Val Loss List: ', val_loss_list)\n",
    "# print('Acc List: ', f1_score_list)\n",
    "\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6188d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and Load the Model\n",
    "saved_model = LSTM(EMBEDDING_DIM, \n",
    "                   HIDDEN_DIM, \n",
    "                   OUTPUT_DIM, \n",
    "                   NUM_LAYERS, \n",
    "                   BIDIRECTION, \n",
    "                   DROPOUT).to(device)\n",
    "\n",
    "saved_model.load_state_dict(torch.load(PATH))\n",
    "saved_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec96c585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text):\n",
    "    text_list = [word for word in tokenize(text.to_string())]\n",
    "    text_vector = []\n",
    "    for word in text_list:\n",
    "        if word in word2idx:\n",
    "            text_vector.append(word2idx[word])\n",
    "        else:\n",
    "            text_vector.append(1)\n",
    "    padded_text_vector = text_vector + [word2idx['<pad>']] * (MAX_LENGTH - len(text_vector))\n",
    "    return torch.from_numpy(np.array(padded_text_vector))\n",
    "            \n",
    "def predict(data):\n",
    "    tag_list = []\n",
    "    with torch.no_grad():\n",
    "        for idx, row in test_df.iterrows():\n",
    "            text_tensor = vectorize_text(row)\n",
    "            # Using Forward Pass of LSTM for Predictions\n",
    "            tag_tensor = saved_model.forward(text_tensor)\n",
    "            tag_tensor = tag_tensor.view(-1, tag_tensor.shape[-1])\n",
    "            max_tensor = tag_tensor.argmax(dim = 1, keepdim = True)\n",
    "            predictions_iob = convert_idx_to_tags(slice_list(squeezed_list(max_tensor)))\n",
    "            tag_list.append(predictions_iob)\n",
    "    return tag_list\n",
    "        \n",
    "iob_preds_list = predict(test_df)\n",
    "iob_preds_list = np.squeeze(np.array(iob_preds_list))\n",
    "iob_preds_list = iob_preds_list.tolist()\n",
    "\n",
    "def truncate_padding(my_list):\n",
    "    trucated_list = []\n",
    "    for element in my_list:\n",
    "        truncated_el = []\n",
    "        for tag in element:\n",
    "            if(tag != '<pad>'):\n",
    "                truncated_el.append(tag)\n",
    "        trucated_list.append(truncated_el)\n",
    "    return trucated_list\n",
    "\n",
    "truncated_iob_list = truncate_padding(iob_preds_list)\n",
    "\n",
    "# Creating Dictionary\n",
    "list_of_dict = []\n",
    "for i in range(0, len(truncated_iob_list)):\n",
    "    temp_dict = {}\n",
    "    temp_dict[\"ID\"] = i\n",
    "    temp_dict[\"IOB Slot tags\"] = ' '.join(truncated_iob_list[i])\n",
    "    list_of_dict.append(temp_dict)\n",
    "\n",
    "# Converting Dictionary to CSV and compressing it for submission to CodaLab\n",
    "tags_df = pd.DataFrame.from_dict(list_of_dict)\n",
    "tags_df.to_csv('submission.csv.zip', compression = 'zip', index = False)\n",
    "print(tags_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
